# -*- coding: utf-8 -*-
"""copy-of-starter_signs_v2_student.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/jluke-russell/d4c96f92d7298ccb85dd8b127f7ea0c6/copy-of-starter_signs_v2_student.ipynb
"""

#Getting model link: https://keras.io/api/applications/

# Note: After you run this cell, the training and test data will be available in
# the file browser. (Click the folder icon on the left to view it)
#
# If you don't see the data after the cell completes, click the refresh button
# in the file browser (folder icon with circular arrow)

# First, let's download and unzip the data
!echo "Downloading files..."
!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training1.zip
!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training2.zip
!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test.zip
!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test_partial.zip
!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test_classes_partial.csv

# !echo "Unzipping files..."
# !unzip -q /content/training1.zip
# !unzip -q /content/training2.zip
# !unzip -q /content/test.zip
# !unzip -q /content/test_partial.zip

# Combine the two traning directories
!echo "Merging training data..."
!mkdir /content/training
!mv /content/training1/* /content/training
!mv /content/training2/* /content/training

# Cleanup
!echo "Cleaning up..."
!rmdir /content/training1
!rmdir /content/training2
!rm training1.zip
!rm training2.zip
!rm test.zip
!rm test_partial.zip

!echo "Data ready."

# Import libraries
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import os
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.utils import Sequence
import sklearn as sk
from sklearn.metrics import classification_report
#import model from keras.applications.xception import xception,decode_predictions

# We're using keras' ImageDataGenerator class to load our image data.
# See (https://keras.io/api/preprocessing/image/#imagedatagenerator-class) for details
#
# A couple of things to note:
# 1. We're specifying a number for the seed, so we'll always get the same shuffle and split of our images.
# 2. Class names are inferred automatically from the image subdirectory names.
# 3. We're splitting the training data into 80% training, 20% validation.


training_dir = '/content/training/'
image_size = (100, 100)

# Split up the training data images into training and validations sets
# We'll use and ImageDataGenerator to do the splits
# ImageDataGenerator can also be used to do preprocessing and agumentation on the files as can be seen with rescale

train_datagen = ImageDataGenerator(
        rescale=1./255,
        validation_split=.2,
        rotation_range = 40,
        width_shift_range = 0.2,
        height_shift_range = 0.2,
        horizontal_flip = True,
        vertical_flip = True,
        brightness_range = [0.3, 0.8],
        zoom_range = 0.2
        )
validation_datagen = ImageDataGenerator(
        rescale=1./255,
        validation_split=.2,
        rotation_range = 40,
        width_shift_range = 0.2,
        height_shift_range = 0.2,
        horizontal_flip = True,
        vertical_flip = True,
        brightness_range = [0.3, 0.8],
        zoom_range = 0.2
        )

train_generator = train_datagen.flow_from_directory(
        training_dir,
        target_size = image_size,
        subset="training",
        batch_size=32,
        class_mode='sparse',
        seed=42,shuffle=True)
validation_generator = validation_datagen.flow_from_directory(
        training_dir,
        target_size=image_size,
        batch_size=32,
        class_mode='sparse',
        subset="validation",
        seed=42)

# View 9 images and their class labels
plt.figure(figsize=(10, 10))
for images, labels in train_generator:
    for i in range(9):
        first_image = images.tolist()[i]
        ax = plt.subplot(3, 3, i + 1)
        f = np.array(first_image)*255
        plt.imshow(f.astype("uint8"))
        plt.title(int(labels[i]))
        plt.axis("off")
    break

# Build a model...
#model=tf.keras.applications.xception.Xception(weights='imagenet',include_top=True) #Call model

# Luke's Vanilla Model
# Import libraries
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import datasets, layers, models
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np

train_datagen = ImageDataGenerator(
        rescale=1./255,
        validation_split=.2
        )
validation_datagen = ImageDataGenerator(
        rescale=1./255,
        validation_split=.2
        )

train_generator = train_datagen.flow_from_directory(
        training_dir,
        target_size=image_size,
        subset="training",
        batch_size=32,
        class_mode='sparse',
        seed=42,
        shuffle=True
        )
validation_generator = validation_datagen.flow_from_directory(
        training_dir,
        target_size=image_size,
        batch_size=32,
        class_mode='sparse',
        subset="validation",
        seed=42
        )

# Build the CNN model
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dense(43, activation='softmax'))

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(
      train_generator,
      steps_per_epoch=train_generator.samples // train_generator.batch_size,
      epochs=15,
      validation_data=validation_generator,
      validation_steps=validation_generator.samples // validation_generator.batch_size
)

# Evaluate the model
test_dir = '/content/test/'
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=image_size,
        batch_size=32,
        class_mode='sparse',
        shuffle=False
)

# Luke's Testing

from tensorflow.keras.preprocessing import image_dataset_from_directory
test_dir = '/content/'

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
        test_dir,
        classes=['test_partial'],
        target_size=image_size,
        class_mode='sparse',
        shuffle=False)
probabilities = model.predict(test_generator)
predictions = [np.argmax(probas) for probas in probabilities]

# Luke's Metrics

import csv
import numpy as np
from sklearn.metrics import f1_score
from sklearn.metrics import classification_report

csv_file = '/content/test_classes_partial.csv'
# Extract the ground truth labels from the CSV file
ground_truth_labels = []

with open(csv_file, 'r') as file:
    reader = csv.reader(file)
    next(reader)  # Skip the header row if present
    for row in reader:
        ground_truth_labels.append(int(row[1]))  # Assuming the labels are in the second column (index 1)

# Convert the ground truth labels to numpy array
ground_truth_labels = np.array(ground_truth_labels)
accuracy = np.mean(predictions == ground_truth_labels)
print(f"Accuracy: {accuracy * 100:.2f}%")
f1 = f1_score(ground_truth_labels, predictions, average='macro')
print(f"F1 Score: {f1:.2f}")

# Calculate Class recall
class_labels = list(validation_generator.class_indices.keys())
recall = classification_report(ground_truth_labels, predictions, labels=range(len(class_labels)), target_names=class_labels)
print("Overall Recall:")
print(recall)

# Calculate overall recall and precision
class_labels = list(validation_generator.class_indices.keys())
classification_report_result = classification_report(ground_truth_labels, predictions, labels=range(len(class_labels)), target_names=class_labels, output_dict=True)
overall_recall = classification_report_result['macro avg']['recall']
overall_precision = classification_report_result['macro avg']['precision']
print("Overall Recall:", overall_recall)
print("Overall Precision:", overall_precision)

"""## Testing the model
Once you have built and trained your model, the next step is to run the test images through it and see how well your model does at making predictions for images it has never seen before.

Since loading these images and formatting them for the model can be tricky, you may find the following code useful. This code only uses your model to predict the class label for a given image. You'll still need to compare those predictions to the "ground truth" class labels in `test_classes_partial.csv` to evaluate how well the model does.



```
from tensorflow.keras.preprocessing import image_dataset_from_directory
test_dir = '/content/'

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
        test_dir,
        classes=['test_partial'],
        target_size=image_size,
        class_mode='sparse',
        shuffle=False)
probabilities = model.predict(test_generator)
predictions = [np.argmax(probas) for probas in probabilities]
```

##Partial Hold out Dataset
You're given the answers to the first 200 images in the hold out dataset.

Once you have predictions for the partial holdout dataset, you'll need to compare those predictions against the "ground truth" class labels in `test_classes_partial.csv` to evaluate how well the model does.

Make sure to use the insights gained from the partial hold out dataset in your executive summary.

Once you feel confident, you will need to predict for the full test dataset using the following code, and submit your csv file:

```
from tensorflow.keras.preprocessing import image_dataset_from_directory
test_dir = '/content/'

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
        test_dir,
        classes=['test'],
        target_size=image_size,
        class_mode='sparse',
        shuffle=False)
probabilities = model.predict(test_generator)
predictions = [np.argmax(probas) for probas in probabilities]
```

KARL'S NOTE:

" *Yes, and just as a technical note, our other smart car products integrate tightly with Apple's CarKit.*
*So whenever you feel like you have a decent model, please save it in a format that we can import into Apple's MLKit framework.* "


More information on DenseNet architecture:
[DenseNet 121 with TensorFlow | Towards Data Science](https://towardsdatascience.com/creating-densenet-121-with-tensorflow-edbc08a956d8)
"""

# Celeste's code
# CURRENTLY TESTING
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dense
from tensorflow.keras.layers import AvgPool2D, GlobalAveragePooling2D, MaxPool2D
from tensorflow.keras.models import Model
from tensorflow.keras.layers import ReLU, concatenate
import tensorflow.keras.backend as K

# DENSENET 121
# Input --> Convolution 1 --> Dense Block 1
#       --> Convolution 2 --> Pooling 1 --> Dense Block 2
#       --> Convolution 3 --> Pooling 2 --> Dense Block 3
#       --> Pooling 3 --> Linear
#       --> Output
# input_pix = Input(train_generator)

# # DONT FORGET TO NORMALIZE THE DATA AT EACH CONVOLUTIONAL LAYER + DROPOUT

# # First covolution block
# # 64 filters of size 7x7 and a stride of 2
# x = Conv2D(64, 7, strides = 2, padding = 'same')(input_pix)
# x = MaxPool2D(3, strides = 2, padding = 'same')(x)

# # Next convolutional blocks
# # BatchNormalization, followed by ReLU activation and then the actual Conv2D layer
# # batch norm + relu + conv
# def bn_rl_conv(x,filters,kernel=1,strides=1):
#     x = BatchNormalization()(x)
#     x = ReLU()(x)
#     x = Conv2D(filters, kernel, strides=strides,padding = 'same')(x)
#     return x

# # Dense blocks
# # 1x1 and 3x3 sized kernels
# # dense block 1: repeated 6 times
# # dense block 2: repeated 12 times
# # dense block 3: 24 times
# # dense block 4: 16 times
# def dense_block(x, repetition):
#    for _ in range(repetition):
#         y = bn_rl_conv(x, 4*filters)
#         y = bn_rl_conv(y, filters, 3)
#         x = concatenate([y,x])
#    return x

# # transition layer: contains convolutional block and pooling
# def transition_layer(x):
#     x = bn_rl_conv(x, K.int_shape(x)[-1] //2 )
#     x = AvgPool2D(2, strides = 2, padding = 'same')(x)
#     return x
# # Repeat transition layers with dense blocks for all repetitions
# for repetition in [6,12,24,16]:
#     d = dense_block(x, repetition)
#     x = transition_layer(d)


# # Pooling
# x = GlobalAveragePooling2D()(d)
# output = Dense(n_classes, activation = 'softmax')(x)

#Early Stop code
#from keras.callbacks import EarlyStopping
#early_stopp = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=3, verbose=0)

#Bridger Inception
from tensorflow.keras import datasets, layers, models#, dropout, BatchNormalization
from tensorflow.keras.applications.inception_v3 import InceptionV3, decode_predictions

model2 = InceptionV3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=(299, 299, 3),
    pooling=None,
    classes=1000,
    classifier_activation='softmax'